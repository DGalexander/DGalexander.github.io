---
layout: post
subtitle: "Analysis of twitteR '#peakdistrict'"
date: "2016-04-09 14:18:00 +0800"
published: true
title: Quantifying visitor sentiment for a National Park
---
## Why access twitter?

Current **customer relationship management (CRM)** systems create customer profiles based on 
demographics, past buying patterns and other interactions or actions. Monitoring and quantifying
interactions of customers with large areas of landscape such as National Parks with regular 
comprehensive visitor surveying is costly and prohibitively expensive. 

The emergance of both **social media mining (SMM)**, other data scienece methods and applications
have provided us with the tools to access this information. This provides a great opportunity to 
develop CRM knowledge and monitoring. 

SMM is not without it's limitations. Preprocessing steps are required to remove the noise and error
from the data. Due to the clutter, which is present in most unstructured data, removing the noise
from data is difficult and not always sucesful. For the purpose of this analysis, not all tweets
will contain sentiment, for example these could be factual or nonsensical.

## How is this done?

Created and app at <https://dev.twitter.com/apps> to access and reqest information from the Twitter
API. The _ROAuth_ package in R is used to allow the third party app to access the Twitter API.

The analysis then follows these steps:

1. Search and Clean Tweets
2. Estimate Sentiment (_Naive Algorithm_)
3. Estimate Sentiment (_Naive Bayes_)

## Search and Clean Tweets

For the purposes of obtainging sentiment of Twitter users we must gather data based on the term
'#peakdistrict'. 

'PDNP_Tweets = searchTwitter("peakdistrict", n = 10000, lang="en")'

Tweets returned are cleaned (4519 observations) based on following perameters (which provide 1310 
observations):

* Meta information usch as @people, URLs and #hashtags
* Punctuation marks, numbers and unnecessary spaces
* retweets (**RT**) not useful for sentiment analysis

## Estimating Sentiment

As mentioned earlier, some Tweets will be , factual, nonesenical or specific such as customer care
resonses. This analysis has not attempted to remove tweets from the data. 

### _Naive Algorithm_ 

The Naive algorithm gives a score based on the number of times a postive of negative word occured
in the given sentence (or Tweet). To do this, the positive and negative _opinion lexicon_ is 
[downloaded](http://www.cs.uic.edu/~liub/FBS/opinion-lexicon-English.rar). This is based on nearly 
68,000 words from the English Language and words categorised to be positive or negative.

Using a simple matching algorithm a _sentiment score_ can be computed. This boolean match of each
word is done for each Tweet, the total positive sentiment score minus the total negative sentiment 
score.

```{r}

```

From the observations, it is clear this 

### _Naive Bayes_

One of the key problems of analytics is to classify entities or events based on a knowledge of their 
attributes. Rather than a simple matching of opinion lexicon, the [_Naive Bayes_](https://en.wikipedia.org/wiki/Bayes%27_theorem)
method helps decide on and classify a series of emotionions present in each Tweet.This uses the 
'Rstem' and 'Sentiment' package. The 'Sentiment' package was built to use a _trained_ dataset of
emotion words (approximatley 1,500). Results can then be generated belonging to one of six emotions:
**anger**, **disgust**, **fear**, **joy**, **sadness** and **surprise**. Not all tweets will contain
data to fit these categories and get disregarded from the analysis.
